{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid (2).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "juHZg7n1mq_B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the csv files into Google drive"
      ]
    },
    {
      "metadata": {
        "id": "7oYged6_JSmO",
        "colab_type": "code",
        "outputId": "216301d8-512c-464f-f7e5-96bba8cfacac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PHR9b3skm9ZA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "importing all the essential directories"
      ]
    },
    {
      "metadata": {
        "id": "xm4deKRr8Kwl",
        "colab_type": "code",
        "outputId": "66863859-0521-4bef-d742-f269115bb018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Model, Sequential, model_from_json\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense, Dropout, Flatten, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, concatenate,Activation\n",
        "from keras import regularizers\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import csv \n",
        "import os\n",
        "from numpy import genfromtxt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gKEC2LY0pIfS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Inception module"
      ]
    },
    {
      "metadata": {
        "id": "p-mHUgguphqG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def inception():\n",
        "    inputs = Input(shape=(480, 640, 3))\n",
        "    input_img = Conv2D(2, (7,7), strides = (2,2), activation='relu')(inputs)\n",
        "    input_img = Conv2D(3, (5,5), activation='relu')(input_img)\n",
        "    \n",
        "    tower_4 = MaxPooling2D((3,3), strides=(2,2), padding='same')(input_img)\n",
        "    \n",
        "    tower_5 = Conv2D(6, (6,6), strides=(2,2), padding='same', activation='relu')(input_img)\n",
        "    \n",
        "    input_img = concatenate([tower_4, tower_5], axis = 3)\n",
        "    \n",
        "    tower_1 = AveragePooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
        "    tower_1 = Conv2D(3, (1,1), padding='same', activation='relu')(tower_1)\n",
        "    \n",
        "    tower_2 = Conv2D(3, (1,1), padding='same', activation='relu')(input_img)\n",
        "    tower_2 = Conv2D(3, (3,3), padding='same', activation='relu')(tower_2)\n",
        "    \n",
        "    tower_3 = Conv2D(3, (1,1), padding='same', activation='relu')(input_img)\n",
        "    tower_3 = Conv2D(3, (5,1), padding='same', activation='relu')(tower_3)\n",
        "    tower_3 = Conv2D(3, (1,5), padding='same', activation='relu')(tower_3)\n",
        "    \n",
        "    outputs = concatenate([tower_1, tower_2, tower_3], axis = 3)\n",
        "    \n",
        "    dense = MaxPooling2D((3, 3), strides=(2,2))(outputs)\n",
        "    dense = Flatten(name='flatten')(dense)\n",
        "    dense = Dense(128, activation='relu', name='dense_1')(dense)\n",
        "    dense = Dropout(0.5)(dense)\n",
        "    dense = Dense(2, name='dense_2')(dense)\n",
        "    \n",
        "    prediction = Activation('sigmoid', name='sigmoid')(dense)\n",
        "    \n",
        "    model = Model(input=inputs, output=prediction)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "licJTJU9pN09",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "compiling the created inception model"
      ]
    },
    {
      "metadata": {
        "id": "afUGGO2ZpNsS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "yi5ie2R73hLb",
        "colab_type": "code",
        "outputId": "f92cd423-bd7a-4e00-f49d-932929334af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "model1=inception()\n",
        "model1.compile(loss=\"mean_squared_error\",optimizer=\"adam\",metrics=['accuracy'])\n",
        "\n",
        "model2=inception()\n",
        "model2.compile(loss=\"mean_squared_error\",optimizer=\"adam\",metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"si...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "peTZHPIPpWSz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "training the images and saving the both the models weights and saving the results in a csv file(result.csv)"
      ]
    },
    {
      "metadata": {
        "id": "wfV-4K_jkw1v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set the path to folder containing training images and train.csv\n",
        "os.chdir('/content/gdrive/My Drive/images')\n",
        "ans=0\n",
        "X_train1=list()\n",
        "Y_train1=list()\n",
        "\n",
        "X_Val1=list()\n",
        "Y_Val1=list()\n",
        "\n",
        "mpg_data = np.genfromtxt('training_set.csv',delimiter=',',dtype=str)\n",
        "\n",
        "for i in range(1,len(mpg_data),240):\n",
        "      img = cv2.imread(mpg_data[i][0])\n",
        "      if img is not None:\n",
        "        X_Val1.append(img)\n",
        "        Y_Val1.append(list(map(int, mpg_data[i][1:3])))\n",
        "X_Val1=np.array(X_Val1)\n",
        "X_Val1=X_Val1/255\n",
        "Y_Val1=np.array(Y_Val1).astype(float)\n",
        "Y_Val1[:,0:2]=Y_Val1[:,0:2]/640.0\n",
        "\n",
        "for i in range(1,len(mpg_data)):\n",
        "\n",
        "    if i%100 ==0:\n",
        "      print(i)\n",
        "      X_train1=np.array(X_train1)\n",
        "      X_train1=X_train1/255\n",
        "      Y_train1=np.array(Y_train1).astype(float)\n",
        "      Y_train1[:,0:2]=Y_train1[:,0:2]/640.0\n",
        "      # Fit the model\n",
        "      model1.fit(X_train1, Y_train1,validation_data=(X_Val1,Y_Val1), epochs=1, batch_size=20)\n",
        "      X_train1=list()\n",
        "      Y_train1=list()\n",
        "\n",
        "    if i!=0:\n",
        "      img = cv2.imread(mpg_data[i][0])\n",
        "      if img is not None:\n",
        "        X_train1.append(img)\n",
        "        Y_train1.append(list(map(int, mpg_data[i][1:3])))\n",
        "    if i%1000 == 0:\n",
        "      model_json = model1.to_json()\n",
        "      with open(\"model_.json\", \"w\") as json_file:\n",
        "          json_file.write(model_json)\n",
        "      # serialize weights to HDF5\n",
        "      model1.save_weights(\"model_a12.h5\")\n",
        "      print(\"Saved model to disk\")\n",
        "\n",
        "X_train2=list()\n",
        "Y_train2=list()\n",
        "\n",
        "X_Val2=list()\n",
        "Y_Val2=list()\n",
        "\n",
        "mpg_data = np.genfromtxt('training_set.csv',delimiter=',',dtype=str)\n",
        "\n",
        "for i in range(1,len(mpg_data),240):\n",
        "      img = cv2.imread(mpg_data[i][0])\n",
        "      if img is not None:\n",
        "        X_Val2.append(img)\n",
        "        Y_Val2.append(list(map(int, mpg_data[i][3:5])))\n",
        "X_Val2=np.array(X_Val2)\n",
        "X_Val2=X_Val2/255\n",
        "Y_Val2=np.array(Y_Val2).astype(float)\n",
        "Y_Val2[:,2:4]=Y_Val2[:,2:4]/480.0\n",
        "\n",
        "for i in range(1,len(mpg_data)):\n",
        "\n",
        "    if i%100 ==0:\n",
        "      print(i)\n",
        "      X_train2=np.array(X_train2)\n",
        "      X_train2=X_train/255\n",
        "      Y_train2=np.array(Y_train2).astype(float)\n",
        "      Y_train2[:,2:4]=Y_train2[:,2:4]/480.0\n",
        "      # Fit the model\n",
        "      model2.fit(X_train2, Y_train2,validation_data=(X_Val2,Y_Val2), epochs=1, batch_size=20)\n",
        "      X_train=list()\n",
        "      Y_train2=list()\n",
        "\n",
        "    if i!=0:\n",
        "      img = cv2.imread(mpg_data[i][0])\n",
        "      if img is not None:\n",
        "        X_train2.append(img)\n",
        "        Y_train2.append(list(map(int, mpg_data[i][3:5])))\n",
        "    if i%1000 == 0:\n",
        "      model_json = model2.to_json()\n",
        "      with open(\"model_.json\", \"w\") as json_file:\n",
        "          json_file.write(model_json)\n",
        "      # serialize weights to HDF5\n",
        "      model2.save_weights(\"model_a13.h5\")\n",
        "      print(\"Saved model to disk\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7wVV1fPIr12F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading the saved inception modules for testing "
      ]
    },
    {
      "metadata": {
        "id": "lfbxsECJXmWH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/gdrive/My Drive/images')\n",
        "loaded_model=inception()\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"model_a12.h5\")\n",
        "loaded_model.compile(loss=\"mean_squared_error\",optimizer=\"adam\",metrics=['accuracy'])\n",
        "\n",
        "model2=inception()\n",
        "# load weights into new model\n",
        "model2.load_weights(\"model_a13.h5\")\n",
        "model2.compile(loss=\"mean_squared_error\",optimizer=\"adam\",metrics=['accuracy'])\n",
        "\n",
        "X_test=list()\n",
        "img_test = list()\n",
        "out = open('result.csv', \"w\")\n",
        "out.write(\"image_name,x1,x2,y1,y2\\n\")\n",
        "mpg_data = np.genfromtxt('test.csv',delimiter=',',dtype=str)\n",
        "\n",
        "for i in range(1,len(mpg_data)):\n",
        "        if i%100 ==0 and i!=0:\n",
        "          print(i)\n",
        "          X_test=np.array(X_test)\n",
        "          X_test=X_test/255\n",
        "          # Fit the model\n",
        "          Y_test1 = loaded_model.predict(X_test)\n",
        "          Y_test2 = model2.predict(X_test)\n",
        "          rows =['']*len(Y_test1)\n",
        "          for j in range(len(Y_test1)):\n",
        "            rows[j]='%s,%s,%s,%s,%s\\n' % (img_test[j],int(Y_test1[j][0]*640),int(Y_test1[j][1]*640),int(Y_test2[j][0]*480),int(Y_test2[j][1]*480))\n",
        "            print(rows[j])\n",
        "          out.writelines(rows)\n",
        "          img_test = list()\n",
        "          X_test = list()\n",
        "        if i!=0:\n",
        "          img = cv2.imread(mpg_data[i][0])\n",
        "          if img is not None:\n",
        "            X_test.append(img)\n",
        "            img_test.append(mpg_data[i][0])\n",
        "\n",
        "X_test=np.array(X_test)\n",
        "X_test=X_test/255\n",
        "# Fit the model\n",
        "Y_test1 = loaded_model.predict(X_test)\n",
        "Y_test2 = model2.predict(X_test)\n",
        "rows =['']*len(Y_test1)\n",
        "for j in range(len(Y_test1)):\n",
        "  rows[j]='%s,%s,%s,%s,%s\\n' % (img_test[j],int(Y_test1[j][0]*640),int(Y_test1[j][1]*640),int(Y_test2[j][0]*480),int(Y_test2[j][1]*480))\n",
        "  print(rows[j])\n",
        "out.writelines(rows)\n",
        "img_test = list()\n",
        "X_test = list()\n",
        "out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XmfjcpjsqgRW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Downloading the result.csv file from drive "
      ]
    },
    {
      "metadata": {
        "id": "hMHaVW3ApbvW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.chdir('/content/gdrive/My Drive/images')\n",
        "from google.colab import files\n",
        "downloaded = files.download('result.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}